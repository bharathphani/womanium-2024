{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85310c8e-1f62-4e4e-b140-bdfe08e42887",
   "metadata": {},
   "source": [
    "## Import pennylane, numpy and optimisers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cd9f0c-ead4-4853-bcd3-bc11e5c89b2f",
   "metadata": {},
   "source": [
    "## Import pennylane, numpy and optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3553d799-57fa-4a82-871e-14a05293b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8242db-e8ed-4a18-9805-68fa1ebb6809",
   "metadata": {},
   "source": [
    "## Create QML nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b29f43-74c0-4778-8c61-e15484786223",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a363f0-d7e9-4e51-85ea-a5d12c6d0179",
   "metadata": {},
   "source": [
    "## State Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e11e6b-e043-4fdf-a4b1-85054c768ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_preparation(x):\n",
    "    qml.BasisState(x, wires=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebda165c-bc38-48e1-9651-48e307504a2c",
   "metadata": {},
   "source": [
    "## Define Layer Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1cd3af5-50b2-487e-b347-46a9db8914d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(layer_weights):\n",
    "    for wire in range(4):\n",
    "        qml.Rot(*layer_weights[wire], wires=wire)\n",
    "\n",
    "    for wires in ([0, 1], [1, 2], [2, 3], [3, 0]):\n",
    "        qml.CNOT(wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e2bd4-6d94-4572-a759-5dff70145c5a",
   "metadata": {},
   "source": [
    "## Define Circuit snd classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb1c25a-234d-4ff0-83a7-a9753d4612c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "    state_preparation(x)\n",
    "\n",
    "    for layer_weights in weights:\n",
    "        layer(layer_weights)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0429fac6-932f-4d22-98ec-f72a37c11832",
   "metadata": {},
   "source": [
    "## Define Loss and cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee1b31e-b771-4832-839a-49fc7d8dfab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    # We use a call to qml.math.stack to allow subtracting the arrays directly\n",
    "    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n",
    "\n",
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca1bbf-17a7-4b68-a646-047f5b328fa6",
   "metadata": {},
   "source": [
    "## Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e83cdba5-0990-4b31-99b4-48a84baf5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "    acc = sum(abs(l - p) < 1e-5 for l, p in zip(labels, predictions))\n",
    "    acc = acc / len(labels)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c6e05-d54d-4953-a457-cf95a43270c7",
   "metadata": {},
   "source": [
    "## Load Data The parity datasetâ€™s train (https://raw.githubusercontent.com/XanaduAI/qml/master/_static/demonstration_assets/variational_classifier/data/parity_train.txt)  and test (https://raw.githubusercontent.com/XanaduAI/qml/master/_static/demonstration_assets/variational_classifier/data/parity_test.txt) sets can be downloaded and should be placed in the subfolder variational_classifier/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffe19b6b-2a30-457d-a93a-edc9a8696106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 0 0 1], y = 1\n",
      "x = [0 0 1 0], y = 1\n",
      "x = [0 1 0 0], y = 1\n",
      "x = [0 1 0 1], y = -1\n",
      "x = [0 1 1 0], y = -1\n",
      "x = [0 1 1 1], y = 1\n",
      "x = [1 0 0 0], y = 1\n",
      "x = [1 0 0 1], y = -1\n",
      "x = [1 0 1 1], y = 1\n",
      "x = [1 1 1 1], y = -1\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"./parity_train.txt\", dtype=int)\n",
    "\n",
    "X = np.array(data[:, :-1])\n",
    "Y = np.array(data[:, -1])\n",
    "Y = Y * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "for x,y in zip(X, Y):\n",
    "    print(f\"x = {x}, y = {y}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9258e5-4577-40da-9233-38843459b221",
   "metadata": {},
   "source": [
    "## initiliaze weights, Biases and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4870c9f0-c044-456c-8518-5aba4e901bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[[ 0.01764052  0.00400157  0.00978738]\n",
      "  [ 0.02240893  0.01867558 -0.00977278]\n",
      "  [ 0.00950088 -0.00151357 -0.00103219]\n",
      "  [ 0.00410599  0.00144044  0.01454274]]\n",
      "\n",
      " [[ 0.00761038  0.00121675  0.00443863]\n",
      "  [ 0.00333674  0.01494079 -0.00205158]\n",
      "  [ 0.00313068 -0.00854096 -0.0255299 ]\n",
      "  [ 0.00653619  0.00864436 -0.00742165]]]\n",
      "Bias:  0.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(\"Weights:\", weights_init)\n",
    "print(\"Bias: \", bias_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c31aae8-0f42-46b0-97c4-b99469509798",
   "metadata": {},
   "source": [
    "## Define optimizer and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e79a9121-97c1-4376-a451-c11eb13cc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83ee15-b16e-4214-a89d-acc56ac88b4a",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d38c0944-6250-4c3d-801a-d90f9f205f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    1 | Cost: 2.3147651 | Accuracy: 0.5000000\n",
      "Iter:    2 | Cost: 1.9664866 | Accuracy: 0.5000000\n",
      "Iter:    3 | Cost: 1.9208589 | Accuracy: 0.5000000\n",
      "Iter:    4 | Cost: 2.6276126 | Accuracy: 0.5000000\n",
      "Iter:    5 | Cost: 0.9323119 | Accuracy: 0.6000000\n",
      "Iter:    6 | Cost: 1.1903549 | Accuracy: 0.5000000\n",
      "Iter:    7 | Cost: 2.0508989 | Accuracy: 0.4000000\n",
      "Iter:    8 | Cost: 1.1275531 | Accuracy: 0.6000000\n",
      "Iter:    9 | Cost: 1.1659803 | Accuracy: 0.6000000\n",
      "Iter:   10 | Cost: 1.1349618 | Accuracy: 0.6000000\n",
      "Iter:   11 | Cost: 0.9994063 | Accuracy: 0.6000000\n",
      "Iter:   12 | Cost: 1.0812559 | Accuracy: 0.6000000\n",
      "Iter:   13 | Cost: 1.2863155 | Accuracy: 0.6000000\n",
      "Iter:   14 | Cost: 2.2658259 | Accuracy: 0.4000000\n",
      "Iter:   15 | Cost: 1.1323724 | Accuracy: 0.6000000\n",
      "Iter:   16 | Cost: 1.3439737 | Accuracy: 0.8000000\n",
      "Iter:   17 | Cost: 2.0076168 | Accuracy: 0.6000000\n",
      "Iter:   18 | Cost: 1.2685760 | Accuracy: 0.5000000\n",
      "Iter:   19 | Cost: 1.6762475 | Accuracy: 0.5000000\n",
      "Iter:   20 | Cost: 1.1868237 | Accuracy: 0.6000000\n",
      "Iter:   21 | Cost: 1.4784687 | Accuracy: 0.6000000\n",
      "Iter:   22 | Cost: 1.4599473 | Accuracy: 0.6000000\n",
      "Iter:   23 | Cost: 0.9573269 | Accuracy: 0.6000000\n",
      "Iter:   24 | Cost: 1.1657424 | Accuracy: 0.5000000\n",
      "Iter:   25 | Cost: 1.0877087 | Accuracy: 0.4000000\n",
      "Iter:   26 | Cost: 1.1683687 | Accuracy: 0.6000000\n",
      "Iter:   27 | Cost: 2.1141689 | Accuracy: 0.6000000\n",
      "Iter:   28 | Cost: 1.0272966 | Accuracy: 0.5000000\n",
      "Iter:   29 | Cost: 0.9664085 | Accuracy: 0.5000000\n",
      "Iter:   30 | Cost: 1.1287654 | Accuracy: 0.6000000\n",
      "Iter:   31 | Cost: 1.4202360 | Accuracy: 0.4000000\n",
      "Iter:   32 | Cost: 1.1286000 | Accuracy: 0.5000000\n",
      "Iter:   33 | Cost: 1.9594333 | Accuracy: 0.4000000\n",
      "Iter:   34 | Cost: 1.2811832 | Accuracy: 0.4000000\n",
      "Iter:   35 | Cost: 0.8522775 | Accuracy: 0.7000000\n",
      "Iter:   36 | Cost: 1.4765281 | Accuracy: 0.6000000\n",
      "Iter:   37 | Cost: 0.9603287 | Accuracy: 0.6000000\n",
      "Iter:   38 | Cost: 1.6031314 | Accuracy: 0.6000000\n",
      "Iter:   39 | Cost: 1.1700888 | Accuracy: 0.4000000\n",
      "Iter:   40 | Cost: 1.7571779 | Accuracy: 0.4000000\n",
      "Iter:   41 | Cost: 1.9608116 | Accuracy: 0.6000000\n",
      "Iter:   42 | Cost: 2.0802752 | Accuracy: 0.6000000\n",
      "Iter:   43 | Cost: 1.1904884 | Accuracy: 0.3000000\n",
      "Iter:   44 | Cost: 0.9941585 | Accuracy: 0.6000000\n",
      "Iter:   45 | Cost: 1.0709609 | Accuracy: 0.5000000\n",
      "Iter:   46 | Cost: 0.9780625 | Accuracy: 0.6000000\n",
      "Iter:   47 | Cost: 1.1573709 | Accuracy: 0.6000000\n",
      "Iter:   48 | Cost: 1.0235239 | Accuracy: 0.6000000\n",
      "Iter:   49 | Cost: 1.2842469 | Accuracy: 0.5000000\n",
      "Iter:   50 | Cost: 0.8549226 | Accuracy: 0.6000000\n",
      "Iter:   51 | Cost: 0.5136787 | Accuracy: 1.0000000\n",
      "Iter:   52 | Cost: 0.2488031 | Accuracy: 1.0000000\n",
      "Iter:   53 | Cost: 0.0461277 | Accuracy: 1.0000000\n",
      "Iter:   54 | Cost: 0.0293518 | Accuracy: 1.0000000\n",
      "Iter:   55 | Cost: 0.0205454 | Accuracy: 1.0000000\n",
      "Iter:   56 | Cost: 0.0352514 | Accuracy: 1.0000000\n",
      "Iter:   57 | Cost: 0.0576767 | Accuracy: 1.0000000\n",
      "Iter:   58 | Cost: 0.0291305 | Accuracy: 1.0000000\n",
      "Iter:   59 | Cost: 0.0127137 | Accuracy: 1.0000000\n",
      "Iter:   60 | Cost: 0.0058108 | Accuracy: 1.0000000\n",
      "Iter:   61 | Cost: 0.0018002 | Accuracy: 1.0000000\n",
      "Iter:   62 | Cost: 0.0014089 | Accuracy: 1.0000000\n",
      "Iter:   63 | Cost: 0.0017489 | Accuracy: 1.0000000\n",
      "Iter:   64 | Cost: 0.0021282 | Accuracy: 1.0000000\n",
      "Iter:   65 | Cost: 0.0029876 | Accuracy: 1.0000000\n",
      "Iter:   66 | Cost: 0.0035331 | Accuracy: 1.0000000\n",
      "Iter:   67 | Cost: 0.0035540 | Accuracy: 1.0000000\n",
      "Iter:   68 | Cost: 0.0025639 | Accuracy: 1.0000000\n",
      "Iter:   69 | Cost: 0.0019459 | Accuracy: 1.0000000\n",
      "Iter:   70 | Cost: 0.0015856 | Accuracy: 1.0000000\n",
      "Iter:   71 | Cost: 0.0008439 | Accuracy: 1.0000000\n",
      "Iter:   72 | Cost: 0.0005960 | Accuracy: 1.0000000\n",
      "Iter:   73 | Cost: 0.0003122 | Accuracy: 1.0000000\n",
      "Iter:   74 | Cost: 0.0002446 | Accuracy: 1.0000000\n",
      "Iter:   75 | Cost: 0.0001745 | Accuracy: 1.0000000\n",
      "Iter:   76 | Cost: 0.0001215 | Accuracy: 1.0000000\n",
      "Iter:   77 | Cost: 0.0001141 | Accuracy: 1.0000000\n",
      "Iter:   78 | Cost: 0.0001538 | Accuracy: 1.0000000\n",
      "Iter:   79 | Cost: 0.0001871 | Accuracy: 1.0000000\n",
      "Iter:   80 | Cost: 0.0001330 | Accuracy: 1.0000000\n",
      "Iter:   81 | Cost: 0.0001380 | Accuracy: 1.0000000\n",
      "Iter:   82 | Cost: 0.0001336 | Accuracy: 1.0000000\n",
      "Iter:   83 | Cost: 0.0001483 | Accuracy: 1.0000000\n",
      "Iter:   84 | Cost: 0.0001234 | Accuracy: 1.0000000\n",
      "Iter:   85 | Cost: 0.0001359 | Accuracy: 1.0000000\n",
      "Iter:   86 | Cost: 0.0001268 | Accuracy: 1.0000000\n",
      "Iter:   87 | Cost: 0.0002270 | Accuracy: 1.0000000\n",
      "Iter:   88 | Cost: 0.0000865 | Accuracy: 1.0000000\n",
      "Iter:   89 | Cost: 0.0000774 | Accuracy: 1.0000000\n",
      "Iter:   90 | Cost: 0.0000759 | Accuracy: 1.0000000\n",
      "Iter:   91 | Cost: 0.0000607 | Accuracy: 1.0000000\n",
      "Iter:   92 | Cost: 0.0000523 | Accuracy: 1.0000000\n",
      "Iter:   93 | Cost: 0.0000536 | Accuracy: 1.0000000\n",
      "Iter:   94 | Cost: 0.0000444 | Accuracy: 1.0000000\n",
      "Iter:   95 | Cost: 0.0000384 | Accuracy: 1.0000000\n",
      "Iter:   96 | Cost: 0.0000497 | Accuracy: 1.0000000\n",
      "Iter:   97 | Cost: 0.0000263 | Accuracy: 1.0000000\n",
      "Iter:   98 | Cost: 0.0000229 | Accuracy: 1.0000000\n",
      "Iter:   99 | Cost: 0.0000339 | Accuracy: 1.0000000\n",
      "Iter:  100 | Cost: 0.0000174 | Accuracy: 1.0000000\n"
     ]
    }
   ],
   "source": [
    "weights = weights_init\n",
    "bias = bias_init\n",
    "for it in range(100):\n",
    "\n",
    "    # Update the weights by one optimizer step, using only a limited batch of data\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n",
    "\n",
    "    # Compute accuracy\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "\n",
    "    current_cost = cost(weights, bias, X, Y)\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e00d03-fca1-4dc3-b66b-114cec614af4",
   "metadata": {},
   "source": [
    "## Predictions on Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35bd96e4-936c-4211-a585-38e7f1c1fdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [0 0 0 0], y = -1, pred=-1.0\n",
      "x = [0 0 1 1], y = -1, pred=-1.0\n",
      "x = [1 0 1 0], y = -1, pred=-1.0\n",
      "x = [1 1 1 0], y = 1, pred=1.0\n",
      "x = [1 1 0 0], y = -1, pred=-1.0\n",
      "x = [1 1 0 1], y = 1, pred=1.0\n",
      "Accuracy on unseen data: 1.0\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt(\"./parity_test.txt\", dtype=int)\n",
    "X_test = np.array(data[:, :-1])\n",
    "Y_test = np.array(data[:, -1])\n",
    "Y_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "predictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n",
    "\n",
    "for x,y,p in zip(X_test, Y_test, predictions_test):\n",
    "    print(f\"x = {x}, y = {y}, pred={p}\")\n",
    "\n",
    "acc_test = accuracy(Y_test, predictions_test)\n",
    "print(\"Accuracy on unseen data:\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c26ba5-b4e2-4648-9f15-c57fb4256ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
